{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "  <a href=\"https://ultralytics.com/yolo\" target=\"_blank\">\n",
        "    <img width=\"1024\", src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png\"></a>\n",
        "\n",
        "  [ä¸­æ–‡](https://docs.ultralytics.com/zh/) | [í•œêµ­ì–´](https://docs.ultralytics.com/ko/) | [æ—¥æœ¬èª](https://docs.ultralytics.com/ja/) | [Ğ ÑƒÑÑĞºĞ¸Ğ¹](https://docs.ultralytics.com/ru/) | [Deutsch](https://docs.ultralytics.com/de/) | [FranÃ§ais](https://docs.ultralytics.com/fr/) | [EspaÃ±ol](https://docs.ultralytics.com/es/) | [PortuguÃªs](https://docs.ultralytics.com/pt/) | [TÃ¼rkÃ§e](https://docs.ultralytics.com/tr/) | [Tiáº¿ng Viá»‡t](https://docs.ultralytics.com/vi/) | [Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](https://docs.ultralytics.com/ar/)\n",
        "\n",
        "  <a href=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml\"><img src=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml/badge.svg\" alt=\"Ultralytics CI\"></a>\n",
        "  <a href=\"https://colab.research.google.com/github/ultralytics/notebooks/blob/main/notebooks/how-to-train-ultralytics-yolo-on-medical-pills-dataset.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "  \n",
        "  <a href=\"https://ultralytics.com/discord\"><img alt=\"Discord\" src=\"https://img.shields.io/discord/1089800235347353640?logo=discord&logoColor=white&label=Discord&color=blue\"></a>\n",
        "  <a href=\"https://community.ultralytics.com\"><img alt=\"Ultralytics Forums\" src=\"https://img.shields.io/discourse/users?server=https%3A%2F%2Fcommunity.ultralytics.com&logo=discourse&label=Forums&color=blue\"></a>\n",
        "  <a href=\"https://reddit.com/r/ultralytics\"><img alt=\"Ultralytics Reddit\" src=\"https://img.shields.io/reddit/subreddit-subscribers/ultralytics?style=flat&logo=reddit&logoColor=white&label=Reddit&color=blue\"></a>\n",
        "  \n",
        "  Welcome to the HomeObjects-3K object detection using Ultralytics YOLO26 ğŸš€ notebook! <a href=\"https://github.com/ultralytics/ultralytics\">YOLO26</a> is the latest version of the YOLO (You Only Look Once) AI models developed by <a href=\"https://ultralytics.com\">Ultralytics</a>. We hope that the resources in this notebook will help you get the most out of YOLO26. Please browse the YOLO26 <a href=\"https://docs.ultralytics.com/\">Docs</a> for details, raise an issue on <a href=\"https://github.com/ultralytics/ultralytics\">GitHub</a> for support, and join our <a href=\"https://ultralytics.com/discord\">Discord</a> community for questions and discussions!</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EM2nwU4jshF"
      },
      "source": [
        "# HomeObjects-3K Object Detection using Ultralytics YOLO26\n",
        "\n",
        "This notebook serves as a starting point for training the YOLO26 model on [home objects](https://docs.ultralytics.com/datasets/detect/homeobjects-3k/) detection dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xypoYW_oYZAf"
      },
      "source": [
        "## Dataset Structure\n",
        "\n",
        "The HomeObjects-3K dataset is organized into the following subsets:\n",
        "\n",
        "- **Training Set**: Comprises 2,285 annotated images featuring objects such as sofas, chairs, tables, lamps, and more.\n",
        "\n",
        "- **Validation Set**: Includes 404 annotated images designated for evaluating model performance.\n",
        "\n",
        "## Applications\n",
        "\n",
        "HomeObjects-3K unlocks a broad range of use cases in indoor computer vision, supporting both cutting-edge research and real-world applications:\n",
        "\n",
        "- âœ… **Indoor Object Detection**: Leverage models such as Ultralytics YOLO26 to accurately detect and localize everyday household itemsâ€”like beds, chairs, lamps, and laptops. This enables real-time scene comprehension for indoor environments.\n",
        "\n",
        "- âœ… **Scene Layout Parsing**: Essential for robotics and smart home systems, this capability allows intelligent devices to interpret room layouts by identifying the placement of doors, windows, and furniture, enhancing navigation and interaction.\n",
        "\n",
        "- âœ… **Augmented Reality (AR)**: Power object-aware AR applications by recognizing items such as TVs or wardrobes and overlaying contextual information or visual effects in real time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "## Setup\n",
        "\n",
        "pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware.\n",
        "\n",
        "[![PyPI - Version](https://img.shields.io/pypi/v/ultralytics?logo=pypi&logoColor=white)](https://pypi.org/project/ultralytics/) [![Downloads](https://static.pepy.tech/badge/ultralytics)](https://clickpy.clickhouse.com/dashboard/ultralytics) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ultralytics?logo=python&logoColor=gold)](https://pypi.org/project/ultralytics/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "outputId": "d80898f7-36ce-4263-e40d-e377fcbfaa3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.4.8 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 38.7/112.6 GB disk)\n"
          ]
        }
      ],
      "source": [
        "!uv pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE6ntKojSfSD"
      },
      "source": [
        "## Dataset YAML File\n",
        "\n",
        "A YAML (Yet Another Markup Language) file defines the dataset configuration, including paths, classes, and other pertinent details. ğŸ˜€"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8go3HNgN0WU"
      },
      "source": [
        "```yaml\n",
        "# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license\n",
        "\n",
        "# HomeObjects-3K dataset by Ultralytics\n",
        "# Documentation: https://docs.ultralytics.com/datasets/detect/homeobjects-3k/\n",
        "# Example usage: yolo train data=HomeObjects-3K.yaml\n",
        "# parent\n",
        "# â”œâ”€â”€ ultralytics\n",
        "# â””â”€â”€ datasets\n",
        "#     â””â”€â”€ homeobjects-3K  â† downloads here (390 MB)\n",
        "\n",
        "# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\n",
        "path: homeobjects-3K # dataset root dir\n",
        "train: images/train # train images (relative to 'path') 2285 images\n",
        "val: images/val # val images (relative to 'path') 404 images\n",
        "\n",
        "# Classes\n",
        "names:\n",
        "  0: bed\n",
        "  1: sofa\n",
        "  2: chair\n",
        "  3: table\n",
        "  4: lamp\n",
        "  5: tv\n",
        "  6: laptop\n",
        "  7: wardrobe\n",
        "  8: window\n",
        "  9: door\n",
        "  10: potted plant\n",
        "  11: photo frame\n",
        "\n",
        "# Download script/URL (optional)\n",
        "download: https://github.com/ultralytics/assets/releases/download/v0.0.0/homeobjects-3K.zip\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMV-sNfiSt_X"
      },
      "source": [
        "## Train\n",
        "\n",
        "Train YOLO26 on [Detect](https://docs.ultralytics.com/tasks/detect/), [Segment](https://docs.ultralytics.com/tasks/segment/), [Classify](https://docs.ultralytics.com/tasks/classify/) and [Pose](https://docs.ultralytics.com/tasks/pose/) datasets. See [YOLO26 Train Docs](https://docs.ultralytics.com/modes/train/) for more information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QUgMYUvlNLvy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8e5b258-d424-45cb-d4ee-2d589f818c39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.3MB 303.6MB/s 0.0s\n",
            "Ultralytics 8.4.8 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=HomeObjects-3K.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo26n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "WARNING âš ï¸ Dataset 'HomeObjects-3K.yaml' images not found, missing path '/content/datasets/homeobjects-3K/images/val'\n",
            "\u001b[KDownloading https://ultralytics.com/assets/homeobjects-3K.zip to '/content/datasets/homeobjects-3K.zip': 100% â”â”â”â”â”â”â”â”â”â”â”â” 390.5MB 36.3MB/s 10.8s\n",
            "\u001b[KUnzipping /content/datasets/homeobjects-3K.zip to /content/datasets/homeobjects-3K...: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5386/5386 794.0files/s 6.8s\n",
            "Dataset download success âœ… (18.2s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 95.1MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=12\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5, 3, True]        \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    119808  ultralytics.nn.modules.block.C3k2            [384, 128, 1, True]           \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     34304  ultralytics.nn.modules.block.C3k2            [256, 64, 1, True]            \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     95232  ultralytics.nn.modules.block.C3k2            [192, 128, 1, True]           \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    463104  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True, 0.5, True]\n",
            " 23        [16, 19, 22]  1    245856  ultralytics.nn.modules.head.Detect           [12, 1, True, [64, 128, 256]] \n",
            "YOLO26n summary: 260 layers, 2,508,480 parameters, 2,508,480 gradients, 5.8 GFLOPs\n",
            "\n",
            "Transferred 606/708 items from pretrained weights\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2646.2Â±1118.8 MB/s, size: 137.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/homeobjects-3K/labels/train... 2285 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2285/2285 2.4Kit/s 0.9s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/homeobjects-3K/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1172.9Â±898.3 MB/s, size: 137.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/homeobjects-3K/labels/val... 404 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 404/404 1.2Kit/s 0.3s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/homeobjects-3K/labels/val.cache\n",
            "Plotting labels to /content/runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000625, momentum=0.9) with parameter groups 114 weight(decay=0.0), 126 weight(decay=0.0005), 126 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/train\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/50         3G      1.279      4.069   0.008574        202        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 1.8it/s 1:19\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.1s/it 27.0s\n",
            "                   all        404       3470      0.695      0.195      0.171       0.12\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/50      3.18G      1.283      2.858   0.008713        190        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.5it/s 57.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 3.3it/s 4.0s\n",
            "                   all        404       3470      0.521      0.339      0.325      0.226\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/50      3.38G      1.287      2.486   0.008823        171        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.5it/s 56.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 3.3it/s 3.9s\n",
            "                   all        404       3470      0.463      0.402      0.373      0.257\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/50       3.4G      1.289      2.269   0.008844        211        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 54.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.5it/s 5.2s\n",
            "                   all        404       3470      0.557      0.424      0.421      0.288\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/50      3.41G      1.293       2.08   0.008783        207        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 55.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 3.5it/s 3.7s\n",
            "                   all        404       3470      0.573      0.455      0.465      0.322\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/50      3.43G      1.285      1.957   0.008661        197        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 55.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 3.6it/s 3.7s\n",
            "                   all        404       3470       0.55      0.464      0.502      0.345\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/50      3.44G      1.298       1.85    0.00875        159        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 56.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 3.1it/s 4.2s\n",
            "                   all        404       3470      0.535      0.537      0.542      0.371\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/50      3.46G      1.293       1.77   0.008635        231        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 55.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.6it/s 5.0s\n",
            "                   all        404       3470      0.586      0.546      0.552      0.381\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/50      3.47G      1.276      1.674   0.008614        186        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 55.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.5it/s 5.3s\n",
            "                   all        404       3470      0.622      0.517      0.567      0.397\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/50      3.49G      1.273      1.607   0.008525        198        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 55.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 3.0it/s 4.4s\n",
            "                   all        404       3470      0.594      0.529      0.579      0.403\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/50       3.5G      1.272      1.566   0.008527        155        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 55.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 3.2it/s 4.0s\n",
            "                   all        404       3470      0.646      0.533      0.594      0.416\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/50      3.52G      1.258      1.512   0.008495        214        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 55.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.6it/s 5.0s\n",
            "                   all        404       3470      0.562      0.593      0.581      0.402\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/50      3.53G      1.264      1.497   0.008458        226        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 54.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.6it/s 5.0s\n",
            "                   all        404       3470      0.601      0.582      0.601      0.416\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/50      3.54G       1.26      1.452   0.008416        239        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 54.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.8it/s 4.6s\n",
            "                   all        404       3470      0.638      0.547      0.605       0.42\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/50      3.56G      1.255      1.433   0.008441        156        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 55.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 3.0it/s 4.4s\n",
            "                   all        404       3470      0.644       0.59      0.629      0.442\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/50      3.57G      1.253      1.399   0.008332        158        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.5it/s 56.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.9it/s 4.5s\n",
            "                   all        404       3470       0.61      0.645      0.635      0.442\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/50      3.59G      1.239      1.363   0.008212        209        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 55.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.6it/s 5.0s\n",
            "                   all        404       3470      0.586      0.605      0.609      0.423\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/50       3.6G      1.232       1.34   0.008337        207        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 55.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 3.4it/s 3.9s\n",
            "                   all        404       3470      0.677      0.578      0.633       0.44\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/50      3.62G      1.231      1.305   0.008398        216        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 55.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.9it/s 4.5s\n",
            "                   all        404       3470      0.558      0.616      0.617      0.434\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/50      3.63G      1.231      1.286   0.008185        143        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 55.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.7it/s 4.9s\n",
            "                   all        404       3470      0.644      0.572      0.634      0.444\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/50      3.65G       1.22       1.27   0.008114        163        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 55.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.7it/s 4.9s\n",
            "                   all        404       3470      0.659      0.555      0.635      0.455\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/50      3.66G      1.227      1.255   0.008047        166        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 54.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.9it/s 4.5s\n",
            "                   all        404       3470       0.66      0.584      0.641      0.458\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/50      3.68G      1.216      1.251   0.008047        143        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 55.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 3.1it/s 4.2s\n",
            "                   all        404       3470      0.629      0.625      0.636       0.45\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/50      3.69G      1.204      1.223   0.008081        197        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.5it/s 56.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.9it/s 4.4s\n",
            "                   all        404       3470      0.634      0.639      0.654      0.459\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/50       3.7G      1.196      1.192   0.007829        231        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.5it/s 56.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 3.0it/s 4.3s\n",
            "                   all        404       3470       0.67      0.591      0.641       0.45\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/50      3.72G      1.204       1.18   0.007938        160        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 56.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.7it/s 4.9s\n",
            "                   all        404       3470      0.684      0.626      0.659       0.47\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/50      3.73G      1.204      1.187   0.007887        256        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.5it/s 56.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.8it/s 4.6s\n",
            "                   all        404       3470      0.658      0.653      0.664      0.476\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/50      3.75G      1.192      1.158   0.007858        176        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.5it/s 56.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.9it/s 4.5s\n",
            "                   all        404       3470      0.654       0.65      0.657      0.472\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/50      3.76G      1.189      1.132   0.007748        206        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 55.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.5it/s 5.3s\n",
            "                   all        404       3470      0.684      0.601       0.65      0.468\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/50      3.78G      1.186      1.136   0.007728        164        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 55.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.5it/s 5.2s\n",
            "                   all        404       3470      0.648      0.662      0.662      0.474\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      31/50      3.79G      1.179      1.106    0.00775        233        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 54.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.8it/s 4.7s\n",
            "                   all        404       3470      0.677      0.628      0.658      0.468\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      32/50       3.8G      1.195      1.115   0.007676        218        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 54.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.9it/s 4.5s\n",
            "                   all        404       3470      0.679      0.615      0.663       0.48\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      33/50      3.82G       1.18      1.098   0.007612        245        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 56.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 3.2it/s 4.1s\n",
            "                   all        404       3470      0.705      0.602      0.657      0.472\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      34/50      3.83G      1.163      1.082   0.007558        190        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 55.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 3.0it/s 4.3s\n",
            "                   all        404       3470      0.736      0.616      0.666      0.485\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      35/50      3.85G      1.145      1.048   0.007559        164        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 55.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.7it/s 4.8s\n",
            "                   all        404       3470      0.716       0.61      0.674      0.489\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      36/50      3.86G       1.16      1.063   0.007483        229        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 55.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.7it/s 4.9s\n",
            "                   all        404       3470      0.681      0.649      0.672      0.489\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      37/50      3.88G      1.151      1.047   0.007322        182        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 55.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.6it/s 5.0s\n",
            "                   all        404       3470      0.692      0.607      0.664       0.48\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      38/50      3.89G      1.151      1.043   0.007506        220        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 54.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.9it/s 4.5s\n",
            "                   all        404       3470      0.694      0.644      0.671      0.484\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      39/50      3.91G      1.141      1.027   0.007353        176        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 55.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 3.4it/s 3.8s\n",
            "                   all        404       3470      0.737      0.607      0.672      0.487\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      40/50      3.92G      1.144      1.027   0.007356        191        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 55.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 3.3it/s 4.0s\n",
            "                   all        404       3470      0.678      0.635      0.674       0.49\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      41/50      3.94G      1.108     0.9007   0.008354        100        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.5it/s 56.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 3.0it/s 4.3s\n",
            "                   all        404       3470      0.697      0.619       0.67      0.485\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      42/50      3.95G      1.085     0.8543   0.008137        106        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 54.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.9it/s 4.4s\n",
            "                   all        404       3470      0.712      0.604       0.67       0.48\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      43/50      3.96G      1.078     0.8273   0.008141        118        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.7it/s 53.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.9it/s 4.4s\n",
            "                   all        404       3470      0.665      0.642      0.674       0.48\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      44/50      3.98G      1.076     0.8249   0.007991         96        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.7it/s 53.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 3.1it/s 4.2s\n",
            "                   all        404       3470      0.709      0.627      0.669       0.48\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      45/50      3.99G       1.07      0.807   0.007902        111        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 54.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.8it/s 4.6s\n",
            "                   all        404       3470      0.712      0.619      0.666      0.482\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      46/50      4.01G      1.069     0.8098   0.007829        112        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.7it/s 53.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.7it/s 4.9s\n",
            "                   all        404       3470      0.661      0.646      0.665      0.481\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      47/50      4.02G      1.052     0.7918   0.007845         82        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.7it/s 53.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 3.2it/s 4.0s\n",
            "                   all        404       3470      0.695      0.621      0.673      0.487\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      48/50      4.04G      1.058     0.8038   0.007688        103        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.7it/s 53.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.9it/s 4.4s\n",
            "                   all        404       3470      0.708      0.619      0.665       0.48\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      49/50      4.05G      1.062     0.7896   0.007793        104        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.6it/s 54.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.9it/s 4.5s\n",
            "                   all        404       3470      0.697      0.629      0.662      0.479\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      50/50      4.07G      1.055     0.7841   0.007744        117        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 143/143 2.7it/s 53.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.9it/s 4.5s\n",
            "                   all        404       3470      0.696      0.625      0.666      0.482\n",
            "\n",
            "50 epochs completed in 0.856 hours.\n",
            "Optimizer stripped from /content/runs/detect/train/weights/last.pt, 5.4MB\n",
            "Optimizer stripped from /content/runs/detect/train/weights/best.pt, 5.4MB\n",
            "\n",
            "Validating /content/runs/detect/train/weights/best.pt...\n",
            "Ultralytics 8.4.8 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO26n summary (fused): 122 layers, 2,377,176 parameters, 0 gradients, 5.2 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.4it/s 5.5s\n",
            "                   all        404       3470      0.681      0.637      0.673      0.489\n",
            "                   bed         22         22      0.761      0.723      0.755      0.557\n",
            "                  sofa        286        398      0.816      0.812      0.867      0.667\n",
            "                 chair        154        305      0.681      0.708      0.743      0.511\n",
            "                 table        300        469      0.724       0.72      0.766      0.567\n",
            "                  lamp        199        304      0.532      0.487      0.482      0.299\n",
            "                    tv         51         54      0.785      0.704      0.761      0.617\n",
            "                laptop          3          4      0.524       0.75      0.651      0.563\n",
            "              wardrobe         85        109      0.683      0.474      0.577      0.395\n",
            "                window        162        371      0.565      0.434      0.469       0.29\n",
            "                  door         58         85      0.569      0.447      0.493      0.351\n",
            "          potted plant        318        788      0.735      0.621      0.691      0.386\n",
            "           photo frame        211        561      0.794      0.762      0.824      0.667\n",
            "Speed: 0.2ms preprocess, 3.0ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/train\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolo26n.pt\")  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Train the model\n",
        "results = model.train(data=\"HomeObjects-3K.yaml\", epochs=50, imgsz=640)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Hapx6WkS--T"
      },
      "source": [
        "![HomeObject-3K dataset sample image](https://github.com/ultralytics/docs/releases/download/0/homeobjects-3k-dataset-sample.avif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKAUvDAbTEjQ"
      },
      "source": [
        "## Predict\n",
        "\n",
        "YOLO26 may be used directly in the Command Line Interface (CLI) with a yolo command for a variety of tasks and modes and accepts additional arguments, i.e. imgsz=640. See a full list of available [yolo arguments](https://docs.ultralytics.com/usage/cfg/) and other details in the [YOLO26 Predict Docs](https://docs.ultralytics.com/modes/train/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzTbeqK_TB6t",
        "outputId": "bab09e81-fe15-4209-a323-642e49f2da7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[KDownloading https://ultralytics.com/assets/home-objects-sample.jpg to 'home-objects-sample.jpg': 100% â”â”â”â”â”â”â”â”â”â”â”â” 116.7KB 22.8MB/s 0.0s\n",
            "image 1/1 /content/home-objects-sample.jpg: 448x640 1 sofa, 3 tables, 4 lamps, 2 potted plants, 6 photo frames, 58.3ms\n",
            "Speed: 3.5ms preprocess, 58.3ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Results saved to \u001b[1m/content/runs/detect/predict\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "modelp = YOLO(f\"{model.trainer.save_dir}/weights/best.pt\")  # load a fine-tuned model\n",
        "\n",
        "# Inference using the model\n",
        "prediction_results = modelp.predict(\"https://ultralytics.com/assets/home-objects-sample.jpg\", save=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmNKY3rWWsvj"
      },
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://github.com/user-attachments/assets/07e7811e-3677-4982-99f3-5e77e7f62651\" width=\"720\" height=\"460\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWBYYdXhTkN7"
      },
      "source": [
        "## Export\n",
        "\n",
        "Export a YOLO26 model to any supported format below with the `format` argument, i.e. `format=onnx`. See [YOLO26 Export Docs](https://docs.ultralytics.com/modes/export/) for more information.\n",
        "\n",
        "- ğŸ’¡ ProTip: Export to [ONNX](https://docs.ultralytics.com/integrations/onnx/) or [OpenVINO](https://docs.ultralytics.com/integrations/openvino/) for up to 3x CPU speedup.  \n",
        "- ğŸ’¡ ProTip: Export to [TensorRT](https://docs.ultralytics.com/integrations/tensorrt/) for up to 5x GPU speedup.\n",
        "\n",
        "| Format                                                                   | `format` Argument | Model                     | Metadata | Arguments                                                            |\n",
        "|--------------------------------------------------------------------------|-------------------|---------------------------|----------|----------------------------------------------------------------------|\n",
        "| [PyTorch](https://pytorch.org/)                                          | -                 | `yolo26n.pt`              | âœ…        | -                                                                    |\n",
        "| [TorchScript](https://docs.ultralytics.com/integrations/torchscript)     | `torchscript`     | `yolo26n.torchscript`     | âœ…        | `imgsz`, `optimize`, `batch`                                         |\n",
        "| [ONNX](https://docs.ultralytics.com/integrations/onnx)                   | `onnx`            | `yolo26n.onnx`            | âœ…        | `imgsz`, `half`, `dynamic`, `simplify`, `opset`, `batch`             |\n",
        "| [OpenVINO](https://docs.ultralytics.com/integrations/openvino)           | `openvino`        | `yolo26n_openvino_model/` | âœ…        | `imgsz`, `half`, `dynamic`, `int8`, `batch`                          |\n",
        "| [TensorRT](https://docs.ultralytics.com/integrations/tensorrt)           | `engine`          | `yolo26n.engine`          | âœ…        | `imgsz`, `half`, `dynamic`, `simplify`, `workspace`, `int8`, `batch` |\n",
        "| [CoreML](https://docs.ultralytics.com/integrations/coreml)               | `coreml`          | `yolo26n.mlpackage`       | âœ…        | `imgsz`, `half`, `int8`, `nms`, `batch`                              |\n",
        "| [TF SavedModel](https://docs.ultralytics.com/integrations/tf-savedmodel) | `saved_model`     | `yolo26n_saved_model/`    | âœ…        | `imgsz`, `keras`, `int8`, `batch`                                    |\n",
        "| [TF GraphDef](https://docs.ultralytics.com/integrations/tf-graphdef)     | `pb`              | `yolo26n.pb`              | âŒ        | `imgsz`, `batch`                                                     |\n",
        "| [TF Lite](https://docs.ultralytics.com/integrations/tflite)              | `tflite`          | `yolo26n.tflite`          | âœ…        | `imgsz`, `half`, `int8`, `batch`                                     |\n",
        "| [TF Edge TPU](https://docs.ultralytics.com/integrations/edge-tpu)        | `edgetpu`         | `yolo26n_edgetpu.tflite`  | âœ…        | `imgsz`                                                              |\n",
        "| [TF.js](https://docs.ultralytics.com/integrations/tfjs)                  | `tfjs`            | `yolo26n_web_model/`      | âœ…        | `imgsz`, `half`, `int8`, `batch`                                     |\n",
        "| [PaddlePaddle](https://docs.ultralytics.com/integrations/paddlepaddle)   | `paddle`          | `yolo26n_paddle_model/`   | âœ…        | `imgsz`, `batch`                                                     |\n",
        "| [MNN](https://docs.ultralytics.com/integrations/mnn)                     | `mnn`             | `yolo26n.mnn`             | âœ…        | `imgsz`, `batch`, `int8`, `half`                                     |\n",
        "| [NCNN](https://docs.ultralytics.com/integrations/ncnn)                   | `ncnn`            | `yolo26n_ncnn_model/`     | âœ…        | `imgsz`, `half`, `batch`                                             |\n",
        "| [IMX500](https://docs.ultralytics.com/integrations/sony-imx500)          | `imx`             | `yolo26n_imx_model/`      | âœ…        | `imgsz`, `int8`                                                      |\n",
        "| [RKNN](https://docs.ultralytics.com/integrations/rockchip-rknn)          | `rknn`            | `yolo26n_rknn_model/`     | âœ…        | `imgsz`, `batch`, `name`                                             |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "S4nWG40CTlOD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "outputId": "52e15fc7-8780-4801-c6af-8d86c9206d62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.4.8 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "ğŸ’¡ ProTip: Export to OpenVINO format for best performance on Intel hardware. Learn more at https://docs.ultralytics.com/integrations/openvino/\n",
            "YOLO26n summary (fused): 122 layers, 2,377,176 parameters, 0 gradients, 5.2 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/runs/detect/train/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 300, 6) (5.1 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx>=1.12.0,<2.0.0', 'onnxslim>=0.1.71', 'onnxruntime-gpu'] not found, attempting AutoUpdate...\n",
            "Using Python 3.12.12 environment at: /usr\n",
            "Resolved 14 packages in 103ms\n",
            "Prepared 6 packages in 8.93s\n",
            "Installed 6 packages in 269ms\n",
            " + colorama==0.4.6\n",
            " + coloredlogs==15.0.1\n",
            " + humanfriendly==10.0\n",
            " + onnx==1.20.1\n",
            " + onnxruntime-gpu==1.23.2\n",
            " + onnxslim==0.1.82\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 9.6s\n",
            "WARNING âš ï¸ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.20.1 opset 22...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/onnx/_internal/torchscript_exporter/utils.py:1447: OnnxExporterWarning: Exporting to ONNX opset version 22 is not supported. by 'torch.onnx.export()'. The highest opset version supported is 20. To use a newer opset version, consider 'torch.onnx.export(..., dynamo=True)'. \n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/onnx/_internal/torchscript_exporter/symbolic_opset9.py:5353: UserWarning: Exporting aten::index operator of advanced indexing in opset 22 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.82...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 11.3s, saved as '/content/runs/detect/train/weights/best.onnx' (9.4 MB)\n",
            "\n",
            "Export complete (11.8s)\n",
            "Results saved to \u001b[1m/content/runs/detect/train/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=/content/runs/detect/train/weights/best.onnx imgsz=640 \n",
            "Validate:        yolo val task=detect model=/content/runs/detect/train/weights/best.onnx imgsz=640 data=/usr/local/lib/python3.12/dist-packages/ultralytics/cfg/datasets/HomeObjects-3K.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/runs/detect/train/weights/best.onnx'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "modele = YOLO(f\"{model.trainer.save_dir}/weights/best.pt\")  # load a custom trained model\n",
        "\n",
        "# Export the model\n",
        "modele.export(format=\"onnx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlHp09Nueb3d"
      },
      "source": [
        "## ğŸ’¡Citation\n",
        "\n",
        "```bibtex\n",
        "@dataset{Jocher_Ultralytics_Datasets_2025,\n",
        "    author = {Jocher, Glenn and Rizwan, Muhammad},\n",
        "    license = {AGPL-3.0},\n",
        "    month = {May},\n",
        "    title = {Ultralytics Datasets: HomeObjects-3K Detection Dataset},\n",
        "    url = {https://docs.ultralytics.com/datasets/detect/homeobject-3k/},\n",
        "    version = {1.0.0},\n",
        "    year = {2025}\n",
        "}\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}